{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "fn = '/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BinaryClassificationPerformance in module my_measures:\n",
      "\n",
      "class BinaryClassificationPerformance(builtins.object)\n",
      " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
      " |  \n",
      " |  Performance measures to evaluate the fit of a binary classification model, v1.02\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
      " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
      " |  \n",
      " |  compute_measures(self)\n",
      " |      Compute performance measures defined by Flach p. 57\n",
      " |  \n",
      " |  img_indices(self)\n",
      " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for feature building and extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words I want to remove  \n",
    "someStopWords = text.ENGLISH_STOP_WORDS.difference(['off', 'all',\n",
    "                                                    'because',\n",
    "                                                    'been',\n",
    "                                                    'every',\n",
    "                                                    'for',\n",
    "                                                    'get',\n",
    "                                                    'give',\n",
    "                                                    'her',\n",
    "                                                    'hers',\n",
    "                                                    'his',\n",
    "                                                    'made',\n",
    "                                                    'me',\n",
    "                                                    'move',\n",
    "                                                    'my',\n",
    "                                                    'never',\n",
    "                                                    'no',\n",
    "                                                    'not',\n",
    "                                                    'nowhere',\n",
    "                                                    'off',\n",
    "                                                    'put',\n",
    "                                                    'see',\n",
    "                                                    'should',\n",
    "                                                    'some',\n",
    "                                                    'someone',\n",
    "                                                    'then',\n",
    "                                                    'under',\n",
    "                                                    'when',\n",
    "                                                    'why',\n",
    "                                                    'you',\n",
    "                                                    'your',\n",
    "                                                    'yours',\n",
    "                                                    'yourself',\n",
    "                                                    'yourselves',\n",
    "                                                    'ma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    toxic_data = pd.read_csv(fn)\n",
    "\n",
    "\n",
    "    if (not test):\n",
    "        # add an indicator for any toxic, severe toxic, obscene, threat, insult, or indentity hate\n",
    "        toxic_data['any_toxic'] = (toxic_data['toxic'] + toxic_data['severe_toxic'] + toxic_data['obscene'] + toxic_data['threat'] + toxic_data['insult'] + toxic_data['identity_hate'] > 0)\n",
    "    print(\"toxic_data is:\", type(toxic_data))\n",
    "    print(\"toxic_data has\", toxic_data.shape[0], \"rows and\", toxic_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in toxic_data:\")\n",
    "    print(toxic_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in toxic_data:\")\n",
    "    print(toxic_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'toxic' Wikipedia comments in the dataset: \")\n",
    "        print(toxic_data['any_toxic'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        #vectorizer = CountVectorizer(stop_words='english')\n",
    "        #X_vec = vectorizer.fit_transform(toxic_data.comment_text)\n",
    "        #fitted_transformations.append(X_vec)\n",
    "        #X_vec = fitted_transformations[0].transform(toxic_data.comment_text)\n",
    "\n",
    "\n",
    "        # Hashing Vectorizer \n",
    "        hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False, stop_words='english')\n",
    "        X_hv = hv.fit_transform(toxic_data.comment_text, someStopWords)\n",
    "        fitted_transformations.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(toxic_data.comment_text)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_hv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[1].transform(X_hv)\n",
    "    \n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    toxic_data['word_count'] = toxic_data['comment_text'].str.split(' ').str.len()\n",
    "    toxic_data['punc_count'] = toxic_data['comment_text'].str.count(\"\\.\")\n",
    "\n",
    "    X_quant_features = toxic_data[[\"word_count\", \"punc_count\"]]\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_hv, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = toxic_data['any_toxic']\n",
    "    else:\n",
    "        X = fitted_transformations[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(toxic_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, toxic_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test sets from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 159571 rows and 9 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id               object\n",
      "comment_text     object\n",
      "toxic             int64\n",
      "severe_toxic      int64\n",
      "obscene           int64\n",
      "threat            int64\n",
      "insult            int64\n",
      "identity_hate     int64\n",
      "any_toxic          bool\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  any_toxic  \n",
      "0             0        0       0       0              0      False  \n",
      "1             0        0       0       0              0      False  \n",
      "2             0        0       0       0              0      False  \n",
      "3             0        0       0       0              0      False  \n",
      "4             0        0       0       0              0      False  \n",
      "The rate of 'toxic' Wikipedia comments in the dataset: \n",
      "0.10167887648758234\n",
      "Shape of HashingVectorizer X:\n",
      "(159571, 131072)\n",
      "   word_count  punc_count\n",
      "0          42           5\n",
      "1          18           2\n",
      "2          42           3\n",
      "3         112           3\n",
      "4          13           1\n",
      "5          12           1\n",
      "6           8           0\n",
      "7          21           2\n",
      "8          83           7\n",
      "9          12           0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(159571, 131074)\n",
      "(159571, 131074)\n",
      "Shape of X_train and X_test:\n",
      "(127656, 131074)\n",
      "(31915, 131074)\n",
      "Shape of y_train and y_test:\n",
      "(127656,)\n",
      "(31915,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(127656, 11)\n",
      "(31915, 11)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_train.csv', my_random_seed=81)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit (and tune) Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 13007, 'Neg': 114649, 'TP': 6380, 'TN': 59464, 'FP': 55185, 'FN': 6627, 'Accuracy': 0.5157924421883813, 'Precision': 0.10363030942905872, 'Recall': 0.49050511263165986, 'desc': 'ols_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(ols_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 13070, 'Neg': 114586, 'TP': 12967, 'TN': 114484, 'FP': 102, 'FN': 103, 'Accuracy': 0.9983941217020743, 'Precision': 0.9921952712525824, 'Recall': 0.9921193573068094, 'desc': 'svm_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 13070, 'Neg': 114586, 'TP': 12955, 'TN': 114510, 'FP': 76, 'FN': 115, 'Accuracy': 0.9985037914394936, 'Precision': 0.9941677538178191, 'Recall': 0.9912012241775058, 'desc': 'lgs_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log')\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(lgs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 13007, 'Neg': 114649, 'TP': 12749, 'TN': 103299, 'FP': 11350, 'FN': 258, 'Accuracy': 0.9090681205740427, 'Precision': 0.5290261006680775, 'Recall': 0.9801645267932652, 'desc': 'nbs_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X_train), y_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()\n",
    "print(nbs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 13070, 'Neg': 114586, 'TP': 12950, 'TN': 114502, 'FP': 84, 'FN': 120, 'Accuracy': 0.9984019552547472, 'Precision': 0.9935553168635876, 'Recall': 0.9908186687069626, 'desc': 'prc_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X_train, y_train)\n",
    "\n",
    "prc_performance_train = BinaryClassificationPerformance(prc.predict(X_train), y_train, 'prc_train')\n",
    "prc_performance_train.compute_measures()\n",
    "print(prc_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 13007, 'Neg': 114649, 'TP': 10947, 'TN': 114470, 'FP': 179, 'FN': 2060, 'Accuracy': 0.9824606755655825, 'Precision': 0.9839115585115945, 'Recall': 0.8416237410625048, 'desc': 'rdg_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "rdg.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train = BinaryClassificationPerformance(rdg.predict(X_train), y_train, 'rdg_train')\n",
    "rdg_performance_train.compute_measures()\n",
    "print(rdg_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 13007, 'Neg': 114649, 'TP': 0, 'TN': 114649, 'FP': 0, 'FN': 13007, 'Accuracy': 0.8981089803847842, 'Precision': nan, 'Recall': 0.0, 'desc': 'rdf_train'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/ml/final_assignment_1/my_measures.py:25: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  self.performance_measures['Precision'] = self.performance_measures['TP'] / (self.performance_measures['TP'] + self.performance_measures['FP'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "rdf_performance_train = BinaryClassificationPerformance(rdf.predict(X_train), y_train, 'rdf_train')\n",
    "rdf_performance_train.compute_measures()\n",
    "print(rdf_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nbs_performance_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_first_full_iteration.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_first_full_iteration.ipynb#ch0000024?line=0'>1</a>\u001b[0m fits \u001b[39m=\u001b[39m [ svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train, rdg_performance_train, rdf_performance_train]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_first_full_iteration.ipynb#ch0000024?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m fit \u001b[39min\u001b[39;00m fits:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_first_full_iteration.ipynb#ch0000024?line=3'>4</a>\u001b[0m     plt\u001b[39m.\u001b[39mplot(fit\u001b[39m.\u001b[39mperformance_measures[\u001b[39m'\u001b[39m\u001b[39mFP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m fit\u001b[39m.\u001b[39mperformance_measures[\u001b[39m'\u001b[39m\u001b[39mNeg\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_first_full_iteration.ipynb#ch0000024?line=4'>5</a>\u001b[0m              fit\u001b[39m.\u001b[39mperformance_measures[\u001b[39m'\u001b[39m\u001b[39mTP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m fit\u001b[39m.\u001b[39mperformance_measures[\u001b[39m'\u001b[39m\u001b[39mPos\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mbo\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nbs_performance_train' is not defined"
     ]
    }
   ],
   "source": [
    "fits = [ols_performance_train, svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train, rdg_performance_train, rdf_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look at some false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_t = prc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of false positives:\n",
      "19426\n",
      "There was something boring here before\n",
      "* * * * * * * * * \n",
      "29457\n",
      "\"\n",
      "\n",
      "How I rid of this \"\"new\"\" message? its really annoying because its the same message over and over - get rid of this plz\"\n",
      "* * * * * * * * * \n",
      "30088\n",
      "Why do you hate him or her?\n",
      "* * * * * * * * * \n",
      "73065\n",
      "A sockpuppet leave me alone.\n",
      "* * * * * * * * * \n",
      "102117\n",
      "hey you're just mad cause you know its true.\n",
      "* * * * * * * * * \n"
     ]
    }
   ],
   "source": [
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(prc_t)):\n",
    "    if (prc_t[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['any_toxic'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['comment_text'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3155, 'Neg': 28760, 'TP': 1993, 'TN': 27303, 'FP': 1457, 'FN': 1162, 'Accuracy': 0.9179382735390882, 'Precision': 0.5776811594202899, 'Recall': 0.6316957210776545, 'desc': 'prc_test'}\n"
     ]
    }
   ],
   "source": [
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3155, 'Neg': 28760, 'TP': 2024, 'TN': 27246, 'FP': 1514, 'FN': 1131, 'Accuracy': 0.917123609587968, 'Precision': 0.5720746184284907, 'Recall': 0.6415213946117274, 'desc': 'svm_test'}\n"
     ]
    }
   ],
   "source": [
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3155, 'Neg': 28760, 'TP': 2014, 'TN': 27188, 'FP': 1572, 'FN': 1141, 'Accuracy': 0.9149929500234999, 'Precision': 0.5616285554935861, 'Recall': 0.6383518225039619, 'desc': 'lgs_test'}\n"
     ]
    }
   ],
   "source": [
    "lgs_performance_test = BinaryClassificationPerformance(lgs.predict(X_test), y_test, 'lgs_test')\n",
    "lgs_performance_test.compute_measures()\n",
    "print(lgs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3218, 'Neg': 28697, 'TP': 2088, 'TN': 23600, 'FP': 5097, 'FN': 1130, 'Accuracy': 0.804887983706721, 'Precision': 0.2906054279749478, 'Recall': 0.6488502175264139, 'desc': 'nbs_test'}\n"
     ]
    }
   ],
   "source": [
    "nbs_performance_test = BinaryClassificationPerformance(nbs.predict(X_test), y_test, 'nbs_test')\n",
    "nbs_performance_test.compute_measures()\n",
    "print(nbs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 3155, 'Neg': 28760, 'TP': 1993, 'TN': 27303, 'FP': 1457, 'FN': 1162, 'Accuracy': 0.9179382735390882, 'Precision': 0.5776811594202899, 'Recall': 0.6316957210776545, 'desc': 'prc_test'}\n"
     ]
    }
   ],
   "source": [
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [svm_performance_test, lgs_performance_test, prc_performance_test]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">SUBMISSION</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "toxic_data has 153164 rows and 2 columns \n",
      "\n",
      "the data types for each of the columns in toxic_data:\n",
      "id              object\n",
      "comment_text    object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in toxic_data:\n",
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "Shape of HashingVectorizer X:\n",
      "(153164, 131072)\n",
      "   word_count  punc_count\n",
      "0          72          10\n",
      "1          13           1\n",
      "2          16           0\n",
      "3          38           3\n",
      "4           7           1\n",
      "5          16           2\n",
      "6          31           4\n",
      "7           6           1\n",
      "8         109           9\n",
      "9          41           0\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(153164, 131074)\n",
      "(153164, 131074)\n",
      "Shape of X_test for submission:\n",
      "(153164, 131074)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 153,164): \n"
     ]
    }
   ],
   "source": [
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data, X_test_submission = process_raw_data(fn='/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_test.csv', my_random_seed=81, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 153,164): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21271969914601344\n"
     ]
    }
   ],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = svm.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>punc_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "   word_count  punc_count  \n",
       "0          72          10  \n",
       "1          13           1  \n",
       "2          16           0  \n",
       "3          38           3  \n",
       "4           7           1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  prediction\n",
       "0  00001cee341fdb12        True\n",
       "1  0000247867823ef7       False\n",
       "2  00013b17ad220c46       False\n",
       "3  00017563c3f7919a       False\n",
       "4  00017695ad8997eb       False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv('/Users/marcinia/Downloads/ml-master/final_assignment_1/toxiccomments_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Canvas: 1) the CSV file that was written in the previous cell and 2) the url to the repository (GitHub or other) that contains your code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
